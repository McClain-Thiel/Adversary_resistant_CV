# Adversarialy Example Resistant Computer Vision

This was the final project for CS182 at UC Berkeley. The goal was to build a computer vision system that is somewhat resistant to misclassification on [natrual adversarial examples](https://arxiv.org/pdf/1907.07174.pdf). This was particularly challenging for 2 reasons.

1. This is an open problem in the field. No one, including top their reserchers know exactly how to do this.
2. We were seriously limited by our resources. We had about 2 weeks including finals week and close to 0 compute power.

That being said we did manage to produce a training system that was able to outperform traditional models on adversarial examples from imagenet.



See out site [here](https://mcclain-thiel.github.io/Adversary_resistant_CV/).